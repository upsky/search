---------------------
План:
--- До 20.06.2015:
[+] по запросу get=categories к веб-серверу отдавать список (иерархию) категорий.
[-] объекты, которые детектим на первом этапе (до 20.06):
    - цена;
    - срочность.
[+] попробовать символьные н-граммы;
    Качество немного падает; возможно это можно будет использовать, т.к. не нужна пословная морфология и
    исправление опечаток. Но контекстная морфология тут будет выигрывать наверняка.
[-] вероятностная классификация - вектор категорий, или хотя бы вероятность по той, которую задетектили.
    Цель: не хорошо, когда мы по какой-нибудь фигне показываем какую-то категорию.

--- До 28.06.2015:
[-] объекты, которые детектим на первом этапе:
    - цена;
    + срочность.
[-] вероятностная классификация - вектор категорий, или хотя бы вероятность по той, которую задетектили.
    Цель: не хорошо, когда мы по какой-нибудь фигне показываем конкретную категорию.

--- До 05.07.2015:
[+] Балансировка категорий. Лепим маленькие суб-категории (содержимым до ~10 примеров) к родительским.
[+] Возвращать структуру категорий + прокинуть это в сервер.
[+] Запилен фреймворк анализаторов поисковых запросов. Сделан первый маркер-тест.
[+] Обкачан юду:
    + слито по 100 страниц каждой категории верхнего уровня;
    + слит новый рукбрикатор, юду оказывается его меняет.
[-] Объекты, которые детектим на первом этапе:
    - Переделать urgency в обобощённый движок детекор объектов.
    - Цена;
[-] Прикрутить libshorttext или из sklearn, но вероятностный.
    Вероятностная классификация - вектор категорий, или хотя бы вероятность по той, которую задетектили.
    Цель: не хорошо, когда мы по какой-нибудь фигне показываем конкретную категорию.

--- До 12.07.2015:
[+] Возвращаем несколько категорий (если есть);
[+] Возвращаем настоящую вероятность для категорий;
[+] Отсечение тупняков (пока по threshold'у).
    Цель: не хорошо, когда мы по какой-нибудь фигне показываем конкретную категорию.
[-] Объекты, которые детектим на первом этапе:
    - Переделать urgency в обобощённый движок детекор объектов.
    - Цена;
[+/-] Прикрутить libshorttext - пока результаты не очень.
[-] По возможности возвращать топ терминов и их весов для списка категорий (?get=categories).

Конспект исследований:
1. Обучающие данные были получены обкачиванием, юду.
Затем sort | uniq
При таком раскладе качество вырастает хорошо.
2. Был посчитан margin для обучающей выбрки, выборка относительно не плохая, выбросов не очень много. Можно их выкинуть, посмотреть на качество (см learn/downloaders/youdo.com/scan_100pages_sorted_uniqed_margin.xlsx).
3. Балансировка обучающего множества в дереве категорий: balance_category_min=10 - при таком раскладе получается ~86 категорий и субкатегорий.
4. Как обучаем:
$> python learn_and_test.py exp --hier ml/learn/categories_youdo.com_2015.06.30.json --data ml/learn/downloaders/youdo.com/scan_100pages_sorted_uniqed.txt --key fit
В этой же утилите рассчёт марджина, тест классификатора.

--- До 21.07.2015:
[-] Новый ансамбль классификаторов:
    - векторайзер и классификатор для каждой категории - свой;
    - фиттинг векторайзера:
        - попробовать фитить только по обучающим примерам из своей категории;
        - посмотреть, что происходит с вектором, из каких весов он состоит, и что с весами для неизвестных слов? они выкидываются?
        - найти способ вытащить слова и их веса для конкретной категории.
    - построить марджины для обучающих примеров каждой категории, посмотреть, как меняется качество по к-фолдам, если убирать в разных пропорциях "выбросы" из обучающих примеров.
    - перенумеровать категории с 0, а не с 1;
    - сделать измерение качества каждой категории отдельно;
    - измерение качества по k-folds суммарно;
    - pipeline с подбором параметров?
[-] Таки допилить движок парсинга объектов.

---------------------
BackLog:
 + обкачать ещё youdo.com, т.к. не хватает обучающих примеров, если делать классификацию по суб-категориям.
 + ансамбли классифайеров:
    - ансамблинг разделением обучащего мн-ва;
    - ансамблинг по таргетам: кластеризация исходных категорий по обуч мн-ву, выделение синтетических пар над-категорий:
        1. пара: в каждой из категорий находятся наиболее похожие исх.кат;
        2. пара: в каждой из категорий равн.распред-ные противоположные исх.категории в пропорции 50-50;
        3. пара: ... другие смешанные синтетики в прочих пропорциях: 40-60, 30-70, 20-80... с каким-то заранее заданным шагом.
      далее отсечение.
 - в сервер добавить запрос "ver=what", по которому он выдаёт версию с описанием возможностей.
 - заюзать нормальную морфологию + с учётом соседних слов, https://github.com/kmike/pymorphy2
 - попробовать заюзать что-нибудь другое, кроме bag-of-words;
 - try TF-IDF for categories instead of dox;
 + отделить обучалку/тестилку от предиктора, причесать сервер;
 - grid-search, составить таблицу: F1 - algo - algo params;
 + play around the 'analyzer' and 'token normalization' under CountVectorizer;
 - TruncatedSVD, latent semantic analysis???

---------------------
Параметры поиска:
 - услуга (специализация, категория)
 - цена
 - место: город, метро, улица, район
 - время (срочно, утром, днём, вечером, сегодня, завтра, на этой неделе, в этом месяце, в следующем...);
 - способ предоставления услуги: у спеца, у меня (на дому, дома, домой), он-лайн, по скайпу, по телефону, удалённо
 - флаг: записаться онлайн
 - флаг: только с [положительными|хорошими] отзывами
 - пол спеца: мужчина/женщина
 - флаг: недорого, дёшево, дорого, люкс
 - флаг: под ключ;

Признаки:
 - что сделать: починить колесо, вылечить насморк;
 - симптом: сдулось колесо, болит голова, головная боль, насморк;
 - специализация: хорошего врача, врача на дом, сантехник;

Структура:
 - нормализатор (е-ё, lower-case)
 - опечаточник - отдельная задача;
 - морфологический нормализатор - для начала просто стеммер;
 - классификатор (скорее всего несколько классификаторов, каждый вытаскивает свой признак);

---------------------


---------------------
Акинатор - http://ru.akinator.com/:
    - можно построить прикольную игровую штуку, которая будет "угадывать" то, что хочет пользователь.
    - таким-то образом можно на самом деле вытаскивать из реальных пользователей онтологию того, как и из чего состоят их потребности.
    - продумать бы каким образом задавать пользователю так, чтобы убеждаться не только в правильности готовых вопросов, но и простимулировать их к формированию новых, если их в системе пока нет.

---------------------
Thinks:
2015.07.20
    Experiments:
    1. Загружаем данные одной категории
    2. Фиттим на них векторайзер
        - посмотреть, что там внутри векторайзера
        - странсофрмить на векторайзере незнакомый текст - что там внутри?
            = На месте всех известных фич - нули.
    3. Фиттим на них классифайер
    4. Делаем к-фолд на этом классифайере

    Done, выводы:
    = К-фолд показывает достаточно высокую точность на каждой категории в отдельности.
      Но тогда вопрос: не переобучаемся ли мы?
    = Если пробуем К-фолд на ансамбле (OneVsTheRest)
    = Тот факт, что у нас юзаются слова, трудно говорить о переобучении - слова либо совпадают, либо нет.
      Однако какие-то слова имеют больший вес и они решают, а другие меньший вес, и к ним больше терпимости.
      Отсюда два вывода:
       - хорошо бы иметь синонимайзер. Для этого можно заюзать word2vec, чтобы попробовать
         поопределять т.н. квази-синонимы.
         Как вставлять синонимы в запрос:
          - для классификтора можно по идее просто отгружать все такие фичи в одну кучу. Возможно это будет шумом.
          - либо на каждый суб-инстанс запроса, сгенерённый по синонимам, отправлять всё это дело в классификатор,
            а дальше выбирать результат голосованием.
       - в качестве ядра заюзать вообще Баеса и сравнить с СГД-ядром; предполагаю, что байес будет
         не то что не хуже, а лучше на реальных данных.

    ----
    1. Построить свой классифайер с sklearn-подобным интерфейсом, методы:
        fit(X, y)
        predict(X)
        predict_proba(X)
        а). на каждый класс делается свой классификатор с заданным ядром
            (инстанс классификатора передаётся параметром? как копировать инстансы? посмотреть в sklearn)
        б). sklearn.multiclass.OneVsRestClassifier - уже делает это.
    2. Сравнить с обычным СГДклассифайером:
       Замерить к-фолд на ВСЕХ обучающих данных на новом ансамбль-классифайере.
    3. я не заметил особой разницы между тем, когда фиттиш векторайзер по всем текстам или только по текстам категории.
       Думаю, разница будет, когда будем обучаться на доках из других категорий.
    4. Я заметил большие странности с Tfidf-векторайзером
        - он вычисляет очень странные меры, которые неочевидным образом зависят от текста слова (!);
        - он как-то очень слабо использует stop_words, как будто и не выкидывает их совсем. Пример: берём запрос
          "срочно доставить документы" и сравниваем его с "доставить документы". Первый запрос получается с шумом из-за
          слова "срочно". Добавляем слово "срочно" в стоп-слова, пробуем - вероятность от классификатора повыше, но
          НЕ такая же, как и просто без него, не дотягивает.
          Это ж удивительно.
    5. затем заметил, что конечно есть разница между тем, когда фильтруешь содержимое категории по маржину.
       Но тут опять вопрос: не переобучаемс ли.
       И похоже переобучаемся, т.к. мы фитимся и затем детектим запросы совсем из других категорий.
    '''
